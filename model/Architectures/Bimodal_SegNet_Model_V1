# define convolution Block

def convolution_block( block_input, num_filters=256, kernel_size=3, dilation_rate=1, padding="same", use_bias=False ):
    x = layers.Conv2D(num_filters, kernel_size=kernel_size, dilation_rate=dilation_rate,
                      padding="same", use_bias=use_bias, kernel_initializer=keras.initializers.HeNormal())(block_input)
    x = layers.BatchNormalization()(x)
    return tf.nn.relu(x)



def Event_frames_Deeplab(n_classes=10, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):
    # Build the model
    standard_inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    event_input = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    # s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand
    s = standard_inputs
    e = event_input
 
 
  
   
   # Contraction path for standard frames
    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)
    c1 = Dropout(0.2)(c1) 
    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)
    c2 = Dropout(0.2)(c2)  
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)

    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)

    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)
    p4 = MaxPooling2D(pool_size=(2, 2))(c4)

    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)
    c5 = Dropout(0.3)(c5)
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)



    
    # Contraction path for Event frames
    E1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(e)
    E1 = Dropout(0.2)(E1)  
    E1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(E1)
    mp1 = MaxPooling2D((2, 2))(E1)

    E2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(mp1)
    E2 = Dropout(0.2)(E2)  
    E2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(E2)
    mp2 = MaxPooling2D((2, 2))(E2)

    E3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(mp2)
    E3 = Dropout(0.2)(E3)
    E3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(E3)
    mp3 = MaxPooling2D((2, 2))(E3)

    E4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(mp3)
    E4 = Dropout(0.2)(E4)
    E4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(E4)
    mp4 = MaxPooling2D(pool_size=(2, 2))(E4)

    E5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(mp4)
    E5 = Dropout(0.3)(E5)
    E5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(E5)
    
    
    
    

   
   
   # Feature concatenation layers
    cE1 = concatenate([c1, E1])
    cE2 = concatenate([c2, E2])
    cE3 = concatenate([c3, E3])
    cE4 = concatenate([c4, E4])



  
  
   # Dilated Spatial Pyramid Pooling

    std_6 = convolution_block(c5, kernel_size=3, dilation_rate=6)
    std_12 = convolution_block(c5, kernel_size=3, dilation_rate=12)
    std_18 = convolution_block(c5, kernel_size=3, dilation_rate=18)
    std_24 = convolution_block(c5, kernel_size=3, dilation_rate=24)
    event_1 = convolution_block(E5, kernel_size=3, dilation_rate=6)
    x = Concatenate(axis=-1)([std_6, std_12, std_18, std_24, event_1])
    X = convolution_block(x, kernel_size=1)
    

  
  
  # Expansive path
    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)
    u6 = concatenate([u6, cE4])
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)

    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = concatenate([u7, cE3])
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)

    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = concatenate([u8, cE2])
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)
    c8 = Dropout(0.2)(c8)  
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)

    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = concatenate([u9, cE1], axis=3)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)
    c9 = Dropout(0.2)(c9)  
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)

    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)

    model = Model(inputs=[inputs], outputs=[outputs])

    # NOTE: Compile the model in the main program to make it easy to test with various loss functions
    # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # model.summary()

    return model


